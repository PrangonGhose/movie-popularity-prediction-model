{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Stack Data - Sens Critique - Prangon Ghose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Scrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup # pip install beautifulsoup4\n",
    "import pandas as pd # pip install pandas\n",
    "import numpy as np # pip install numpy\n",
    "import time # pip install time\n",
    "import re # pip install re -- to remove unnecessary spaces in the movie titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data used in this project is from the `Catalogue` page of the `Sens Critique` website. There are 8000 films data in this page. The collected columns are `title`, `name of directors`, `genres`, `Release Year`. The data is dynamically loaded in the `Catalogue` page, hence `selenium` is used to simulate a browser environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver # pip install selenium\n",
    "from selenium.webdriver.chrome.options import Options # import options for chrome\n",
    "from selenium.webdriver.common.by import By # import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait # import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC # import expected_conditions\n",
    "from selenium.common.exceptions import TimeoutException # import TimeoutException\n",
    "from selenium.common.exceptions import NoSuchElementException # import NoSuchElementException\n",
    "from selenium.common.exceptions import ElementNotInteractableException # import ElementClickInterceptedException\n",
    "from selenium.webdriver.common.keys import Keys # import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains # import ActionChains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing browser without GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set up the Chrome WebDriver with headless option\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run Chrome in headless mode (no GUI)\n",
    "\n",
    "prefs = {\n",
    "  \"profile.managed_default_content_settings.images\": 2, \n",
    "  \"profile.managed_default_content_settings.javascript\": 2,\n",
    "  \"profile.managed_default_content_settings.stylesheet\": 2\n",
    "}\n",
    "\n",
    "chrome_options.add_experimental_option(\"prefs\", prefs) # Disable images\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome(options=chrome_options)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As 8000 movies data is dynamically loaded in 500 pages, looping through all the pages and using asynchronous programming are must. To develop the machine learning model for determining movie popularity, only the rating is not enough. The model must know the number of users rated the movie, the number of users bookmarked the movie, and the number of users loved the movie. Sometime the duration of the movie also effects the popularity. That is why these features are necessary to predict a movie popularity.\n",
    "\n",
    "In Sens Critique website some necessary information can be found in the about page of one particular movie. But unfornately in this website coming back to previous page is not possible and also the later pages of the `catalogue` is not accessible directly. And so a different approach of opening a film about page in a new tab is taken to collect those data.\n",
    "\n",
    "**N.B. Collecting 8000 movie data and traversing through each movie about page might take a few minutes. But the result is worth it. Number of pages can be adjusted in between 1-500 to reduce time.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapped Pages: \n",
      "1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50\n",
      "51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100\n",
      "101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150\n",
      "151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200\n",
      "201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250\n",
      "251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300\n",
      "301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350\n",
      "351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400\n",
      "401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450\n",
      "451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500\n"
     ]
    }
   ],
   "source": [
    "page = 1 # page number\n",
    "df_films = pd.DataFrame() # initialize the dataframe\n",
    "\n",
    "def remove_extra_spaces(input_string):\n",
    "  # Using regular expression to replace multiple spaces with a single space as there are some titles with unnecessary spaces\n",
    "  return re.sub(r'\\s+', ' ', input_string).strip()\n",
    "\n",
    "try: # try to load the page\n",
    "  url_sc = 'https://www.senscritique.com/search?filters%5B0%5D%5Bidentifier%5D=universe&filters%5B0%5D%5Bvalue%5D=movie&size=16' # url of the page\n",
    "  driver.get(url_sc) # load the page\n",
    "  # Waiting for up to 10 seconds until the specific element is present in the DOM (the first page)\n",
    "  element_present = EC.presence_of_element_located((By.CLASS_NAME, 'ExplorerProductCard__Container-sc-1l583m3-0')) # finding the element of film data holder\n",
    "  WebDriverWait(driver, 10).until(element_present) # wait until the film data is present in the DOM\n",
    "\n",
    "  print('Scrapped Pages: ')\n",
    "\n",
    "  # Per page has 16 films. But it takes 1 min to scrap 3 pages. So scrapping 500 pages will take approximatedly 3 hours.\n",
    "\n",
    "  while page <= 500: # the total number of pages can be adjusted from 1-500\n",
    "    # Wait for the specific element to be present in the DOM\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\") # parse the page\n",
    "\n",
    "    titles = []\n",
    "    ratings = []\n",
    "    infos = []\n",
    "    genres = []\n",
    "    users_rated = []\n",
    "    users_bookmarked = []\n",
    "    users_loved = []\n",
    "\n",
    "    films = soup.find_all('div', attrs= {'data-testid': 'product-explorer-card'}) # find all the films\n",
    "\n",
    "    for film in range(len(films)): # for each film\n",
    "      if films[film].find('div', attrs={'data-testid': 'Rating'}) is not None:\n",
    "        ratings.append(films[film].find('div', attrs={'data-testid': 'Rating'}).text) # find the rating\n",
    "      else:\n",
    "        ratings.append(np.nan) # if there is no rating, put NaN\n",
    "      if films[film].find('a', attrs={'data-testid': 'product-explorer-title'}) is not None:\n",
    "        title = films[film].find('a', attrs={'data-testid': 'product-explorer-title'}).text # find the title\n",
    "        title = remove_extra_spaces(title) # remove unnecessary spaces\n",
    "        titles.append(title) # find the title\n",
    "      else:\n",
    "        titles.append(np.nan) # if there is no title, put NaN\n",
    "      if films[film].find('p', attrs={'data-testid': 'product-explorer-genre'}) is not None:\n",
    "        genre = films[film].find('p', attrs={'data-testid': 'product-explorer-genre'}).text # find the genre\n",
    "        genres.append(genre)\n",
    "      else:\n",
    "        genres.append(np.nan) # if there is no genre, put NaN\n",
    "\n",
    "      try:\n",
    "        # Attempt to find and click the element\n",
    "        element = driver.find_element(By.LINK_TEXT, title)\n",
    "        if element.is_displayed() and element.is_enabled():\n",
    "          ActionChains(driver).key_down(Keys.CONTROL).click(element).key_up(Keys.CONTROL).perform()\n",
    "          WebDriverWait(driver, 20).until(EC.number_of_windows_to_be(2))\n",
    "\n",
    "        try:\n",
    "          driver.switch_to.window(driver.window_handles[1]) # switch to the new tab\n",
    "          # Waiting for up to 30 seconds until the specific element is present in the DOM (the first page)\n",
    "          element_present = EC.presence_of_element_located((By.CLASS_NAME, 'CoverProductInfos__WrapperStats-sc-1un0kh1-2')) # finding the element of film data holder\n",
    "          WebDriverWait(driver, 30).until(element_present) # wait until the film data is present in the DOM\n",
    "          film_about_soup = BeautifulSoup(driver.page_source, \"html.parser\") # parse the page of the film\n",
    "          if film_about_soup.find('p', class_ = \"Text__SCText-sc-1aoldkr-0\") is not None:\n",
    "            users = film_about_soup.find_all('p', class_ = \"Stats__Text-sc-1u6v943-2\") # find the number of users\n",
    "\n",
    "          if len(users) == 3:\n",
    "            users_rated.append(users[0].text) # append the number of users rated\n",
    "            users_bookmarked.append(users[1].text) # append the number of users bookmarked\n",
    "            users_loved.append(users[2].text) # append the number of users loved\n",
    "          elif len(users) == 2:\n",
    "            users_rated.append(users[0].text)\n",
    "            users_bookmarked.append(users[1].text)\n",
    "            users_loved.append(np.nan)\n",
    "          elif len(users) == 1:\n",
    "            users_rated.append(users[0].text)\n",
    "            users_bookmarked.append(np.nan)\n",
    "            users_loved.append(np.nan)\n",
    "          else:\n",
    "            users_rated.append(np.nan)\n",
    "            users_bookmarked.append(np.nan)\n",
    "            users_loved.append(np.nan)\n",
    "\n",
    "          if film_about_soup.find('p', class_ = 'Creators__Text-sc-1ghc3q0-0') is not None:\n",
    "            infos.append(film_about_soup.find('p', class_ = 'Creators__Text-sc-1ghc3q0-0').text) # find the info\n",
    "          else:\n",
    "            infos.append(np.nan) # if there is no info, put NaN\n",
    "\n",
    "          driver.close() # close the tab\n",
    "          driver.switch_to.window(driver.window_handles[0]) # switch to the main tab\n",
    "\n",
    "        except (TimeoutException, IndexError) as e: # if the page is not loaded\n",
    "          if e == TimeoutException:\n",
    "            print(f\"Timed out waiting for {title}'s about page to load\")\n",
    "            driver.close() # close the tab\n",
    "            driver.switch_to.window(driver.window_handles[0]) # switch to the main tab\n",
    "          else:\n",
    "            print(f\"{title}'s about page is not loaded\")\n",
    "            driver.close() # close the tab\n",
    "          users_rated.append(np.nan)\n",
    "          users_bookmarked.append(np.nan)\n",
    "          users_loved.append(np.nan)\n",
    "          if film_about_soup.find('p', attrs={'data-testid': 'product-explorer-creator'}) is not None:\n",
    "            infos.append(film_about_soup.find('p', attrs={'data-testid': 'product-explorer-creator'}).text) # find the info\n",
    "          else:\n",
    "            infos.append(np.nan) # if there is no info, put NaN\n",
    "\n",
    "      except (NoSuchElementException, ElementNotInteractableException) as e:\n",
    "        users_rated.append(np.nan)\n",
    "        users_bookmarked.append(np.nan)\n",
    "        users_loved.append(np.nan)\n",
    "        if film_about_soup.find('p', attrs={'data-testid': 'product-explorer-creator'}) is not None:\n",
    "          infos.append(film_about_soup.find('p', attrs={'data-testid': 'product-explorer-creator'}).text) # find the info\n",
    "        else:\n",
    "          infos.append(np.nan) # if there is no info, put NaN\n",
    "\n",
    "    df_extracted_films = pd.DataFrame({'titles': titles, 'ratings': ratings, 'infos': infos, 'genres': genres, 'users_rated': users_rated, 'users_bookmarked': users_bookmarked, 'users_loved': users_loved}) # create a dataframe of the extracted films\n",
    "    df_films = pd.concat([df_films, df_extracted_films], ignore_index=True) # concatenate the extracted films to the main dataframe\n",
    "    if page % 50 != 0:\n",
    "      print(page, end = ',')\n",
    "    else:\n",
    "      print(page, end = '\\n')\n",
    "    page += 1 # increment the page number\n",
    "    try:\n",
    "      # Waiting for up to 0.5 seconds until the specific element is present in the DOM. Drawback is the program will run more than 4 mintues for 500 pages.\n",
    "      # element_present = EC.presence_of_element_located((By.CLASS_NAME, 'ExplorerProductCard__Container-sc-1l583m3-0'))\n",
    "      # WebDriverWait(driver, 30).until(element_present)\n",
    "      if page < 501: # the total number of pages is 500\n",
    "        path = \"//span[@data-testid='click-\" + str(page) + \"']\" # find the next page path\n",
    "        next_button = driver.find_element(By.XPATH, path) # find the next page button\n",
    "        next_button.click() # simulate a click the next page button\n",
    "        time.sleep(0.5) # wait for 0.5 seconds\n",
    "    except TimeoutException:\n",
    "      print(f\"Timed out waiting for page {page} to load\")\n",
    "except TimeoutException: # if the page is not loaded\n",
    "  print(\"Timed out waiting for the catalogue page to load\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping any present duplicates and null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films = df_films.drop_duplicates() # drop the duplicates\n",
    "df_films = df_films.dropna() # drop the NaN values\n",
    "df_films = df_films.reset_index(drop=True) # reset the index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract `Directors`, `Duration`, and `Release Date` from `infos` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films['Directors'] = df_films['infos'].str.extract(r'.+ de (.*?) ·') # extract the directors\n",
    "df_films['Duration'] = df_films['infos'].str.extract(r'· (.*?) ·') # extract the duration\n",
    "df_films['Release Date'] = df_films['infos'].str.extract(r'· \\d+ h \\d+ min · (.+?) \\(') # extract the release date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop `infos` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films.drop(columns=['infos'], inplace=True) # drop the infos column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the `Duration` into `Duration (min)` to keep similar unit for future machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_duration(x): # convert the duration to minutes\n",
    "  if x is not np.nan:\n",
    "    if 'h' in x and 'min' in x:\n",
    "      return int(x.split('h')[0]) * 60 + int(x.split('h')[1].split('min')[0])\n",
    "    elif 'h' in x and 'min' not in x:\n",
    "      return int(x.split('h')[0]) * 60\n",
    "    elif 'h' not in x and 'min' in x:\n",
    "      return int(x.split('min')[0])\n",
    "    else:\n",
    "      return int(x)\n",
    "  else:\n",
    "    return x\n",
    "\n",
    "df_films['Duration (min)'] = df_films['Duration'].apply(convert_duration) # apply the convert_duration function to the duration column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films.drop(columns=['Duration'], inplace=True) # drop the duration column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting different users number into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_thousands(x):\n",
    "  if 'K' in x:\n",
    "    return float(x.split('K')[0]) * 1000\n",
    "  else:\n",
    "    return float(x)\n",
    "  \n",
    "df_films['users_rated'] = df_films['users_rated'].apply(convert_thousands) # apply the convert_thousands function to the users_rated column\n",
    "df_films['users_bookmarked'] = df_films['users_bookmarked'].apply(convert_thousands) # apply the convert_thousands function to the users_bookmarked column\n",
    "df_films['users_loved'] = df_films['users_loved'].apply(convert_thousands) # apply the convert_thousands function to the users_loved column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translating the `Release Date` from French to English to convert this into `DateTime`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_month_from_french(x):\n",
    "  month_dict = { # create a dictionary of months\n",
    "    'janvier': 'January',\n",
    "    'février': 'February',\n",
    "    'mars': 'March',\n",
    "    'avril': 'April',\n",
    "    'mai': 'May',\n",
    "    'juin': 'June',\n",
    "    'juillet': 'July',\n",
    "    'août': 'August',\n",
    "    'septembre': 'September',\n",
    "    'octobre': 'October',\n",
    "    'novembre': 'November',\n",
    "    'décembre': 'December'\n",
    "  }\n",
    "\n",
    "  if x is not np.nan:\n",
    "    month_list = x.split(' ')\n",
    "    if len(month_list) == 3: # if variable has day, month, and year\n",
    "      month_list[1] = month_dict[month_list[1]]\n",
    "    elif len(month_list) == 2: # if variable has month and year\n",
    "      month_list[0] = month_dict[month_list[0]]\n",
    "    elif len(month_list) == 1 and month_list[0] in month_dict: # if variable has only month\n",
    "      month_list[0] = month_dict[month_list[0]]\n",
    "    else: # if variable has only year\n",
    "      pass\n",
    "    return ' '.join(month_list)\n",
    "  else:\n",
    "    return x\n",
    "  \n",
    "df_films['Release Date'] = df_films['Release Date'].apply(translate_month_from_french) # apply the translate_month_from_french function to the Release Date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films['Release Date'] = pd.to_datetime(df_films['Release Date'], format='%d %B %Y', errors='coerce') # convert the Release Date column to datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the cleaned dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>ratings</th>\n",
       "      <th>genres</th>\n",
       "      <th>users_rated</th>\n",
       "      <th>users_bookmarked</th>\n",
       "      <th>users_loved</th>\n",
       "      <th>Directors</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Duration (min)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fight Club</td>\n",
       "      <td>8.1</td>\n",
       "      <td>Drame</td>\n",
       "      <td>246800.0</td>\n",
       "      <td>23900.0</td>\n",
       "      <td>14100.0</td>\n",
       "      <td>David Fincher</td>\n",
       "      <td>1999-11-10</td>\n",
       "      <td>139.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>8.3</td>\n",
       "      <td>Gangster, Comédie</td>\n",
       "      <td>228400.0</td>\n",
       "      <td>27700.0</td>\n",
       "      <td>12400.0</td>\n",
       "      <td>Quentin Tarantino</td>\n",
       "      <td>1994-10-26</td>\n",
       "      <td>154.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inception</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Action, Thriller, Science-fiction</td>\n",
       "      <td>219300.0</td>\n",
       "      <td>22600.0</td>\n",
       "      <td>8900.0</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>2010-07-21</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Inglourious Basterds</td>\n",
       "      <td>7.4</td>\n",
       "      <td>Drame, Guerre</td>\n",
       "      <td>180600.0</td>\n",
       "      <td>15800.0</td>\n",
       "      <td>6400.0</td>\n",
       "      <td>Quentin Tarantino</td>\n",
       "      <td>2009-08-19</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Avatar</td>\n",
       "      <td>6.4</td>\n",
       "      <td>Action, Aventure, Science-fiction</td>\n",
       "      <td>157100.0</td>\n",
       "      <td>11800.0</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>2009-12-16</td>\n",
       "      <td>162.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7862</th>\n",
       "      <td>La Jalousie</td>\n",
       "      <td>6.4</td>\n",
       "      <td>Drame</td>\n",
       "      <td>969.0</td>\n",
       "      <td>811.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Philippe Garrel</td>\n",
       "      <td>2013-12-04</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7863</th>\n",
       "      <td>Compañeros</td>\n",
       "      <td>7.1</td>\n",
       "      <td>Biopic, Historique</td>\n",
       "      <td>732.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>Alvaro Brechner</td>\n",
       "      <td>2019-03-27</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7864</th>\n",
       "      <td>Un baiser s'il vous plaît</td>\n",
       "      <td>6.4</td>\n",
       "      <td>Comédie romantique</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>Emmanuel Mouret</td>\n",
       "      <td>2007-12-12</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7865</th>\n",
       "      <td>Les Gardiennes</td>\n",
       "      <td>5.9</td>\n",
       "      <td>Drame</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Xavier Beauvois</td>\n",
       "      <td>2017-12-06</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7866</th>\n",
       "      <td>Les Tribulations d'une caissière</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Comédie</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Pierre Rambaldi</td>\n",
       "      <td>2011-12-14</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7867 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                titles ratings  \\\n",
       "0                           Fight Club     8.1   \n",
       "1                         Pulp Fiction     8.3   \n",
       "2                            Inception     7.5   \n",
       "3                 Inglourious Basterds     7.4   \n",
       "4                               Avatar     6.4   \n",
       "...                                ...     ...   \n",
       "7862                       La Jalousie     6.4   \n",
       "7863                        Compañeros     7.1   \n",
       "7864         Un baiser s'il vous plaît     6.4   \n",
       "7865                    Les Gardiennes     5.9   \n",
       "7866  Les Tribulations d'une caissière     4.7   \n",
       "\n",
       "                                 genres  users_rated  users_bookmarked  \\\n",
       "0                                 Drame     246800.0           23900.0   \n",
       "1                     Gangster, Comédie     228400.0           27700.0   \n",
       "2     Action, Thriller, Science-fiction     219300.0           22600.0   \n",
       "3                         Drame, Guerre     180600.0           15800.0   \n",
       "4     Action, Aventure, Science-fiction     157100.0           11800.0   \n",
       "...                                 ...          ...               ...   \n",
       "7862                              Drame        969.0             811.0   \n",
       "7863                 Biopic, Historique        732.0            1100.0   \n",
       "7864                 Comédie romantique       1400.0             406.0   \n",
       "7865                              Drame       1200.0             597.0   \n",
       "7866                            Comédie       1600.0             225.0   \n",
       "\n",
       "      users_loved          Directors Release Date  Duration (min)  \n",
       "0         14100.0      David Fincher   1999-11-10           139.0  \n",
       "1         12400.0  Quentin Tarantino   1994-10-26           154.0  \n",
       "2          8900.0  Christopher Nolan   2010-07-21           148.0  \n",
       "3          6400.0  Quentin Tarantino   2009-08-19           153.0  \n",
       "4          3400.0      James Cameron   2009-12-16           162.0  \n",
       "...           ...                ...          ...             ...  \n",
       "7862         55.0    Philippe Garrel   2013-12-04            77.0  \n",
       "7863         59.0    Alvaro Brechner   2019-03-27           122.0  \n",
       "7864         73.0    Emmanuel Mouret   2007-12-12            96.0  \n",
       "7865         33.0    Xavier Beauvois   2017-12-06           134.0  \n",
       "7866         22.0    Pierre Rambaldi   2011-12-14           102.0  \n",
       "\n",
       "[7867 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_films"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe is ready to be used for the analysis and building a machine learning algorithm. The next step is to determine necessary features to be included in the algorithm. In my opinion, the features that can be used are: `ratings, users_rated, users_bookmarked, users_loved, Duraion (min), and Release Date`. In order to include this many features, I will use the Random Forest algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films.to_json('sens-critique.json', orient='records') # save the dataframe to json file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
